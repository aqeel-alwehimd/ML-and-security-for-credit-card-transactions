{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67f6b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>trans</th>\n",
       "      <th>ratio</th>\n",
       "      <th>repeat</th>\n",
       "      <th>chip</th>\n",
       "      <th>pin</th>\n",
       "      <th>online</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        home     trans     ratio  repeat  chip  pin  online  fraud\n",
       "0  57.877857  0.311140  1.945940     1.0   1.0  0.0     0.0    0.0\n",
       "1  10.829943  0.175592  1.294219     1.0   0.0  0.0     0.0    0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"card_transdata.csv\")\n",
    "df = df.rename(columns={'distance_from_home': 'home', \n",
    "                        'distance_from_last_transaction': 'trans', \n",
    "                        'ratio_to_median_purchase_price': \"ratio\",\n",
    "                        'repeat_retailer': \"repeat\",\n",
    "                        'used_chip': 'chip',\n",
    "                        'used_pin_number': 'pin',\n",
    "                        'online_order': 'online'})\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec188e4d",
   "metadata": {},
   "source": [
    "So Splitting the data will surely create an imbalance of 9/1, which will cause issues when training the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5256289",
   "metadata": {},
   "source": [
    "I'm going to test oversampling and undersampling on the training data and see how different linear models behave in terms of Recall instead of just accuracy. I will also use an ensemble of RandomForest trees and test these cost-sensitive models with different parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4129d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use sklean as it provides easy and basic model interpretability.\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.svm import SVC as svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f85973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the predictors from the responses\n",
    "X = df.drop([\"fraud\"], axis=1)\n",
    "y = df[\"fraud\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c85ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will first scale the non-binary features to get better readability for the machine\n",
    "\n",
    "non_binary = [\"home\", \"trans\", \"ratio\"]\n",
    "binary = [\"repeat\", \"chip\", \"pin\", \"online\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[non_binary])\n",
    "\n",
    "# fitting and transforming seperate to prevent data leakage\n",
    "X_train[non_binary] = scaler.transform(X_train[non_binary])\n",
    "X_test[non_binary] = scaler.transform(X_test[non_binary])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0284286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So first I will apply cross validation to get an idea of \n",
    "# what might be the best model to use in this case\n",
    "# LogisticRegression, random forests, and SVM\n",
    "\n",
    "log = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62bbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the default n_estimators which is 100 trees\n",
    "# Although this takes a bit of time on a regular computer\n",
    "# Since it fits 1m observations. However, it is needed\n",
    "# for the purpose of this project.\n",
    "\n",
    "forest = RandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9426aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the default RBF kernel for SVM as well\n",
    "# I will reduce the amount of fitting data since SVM's\n",
    "# take more complexity than other models\n",
    "# even though this will be costy for the model, but for the sake\n",
    "# of comparison this will do\n",
    "\n",
    "svm = svc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14568b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69249395, 0.69969252, 0.70625   , 0.70652545, 0.71840659])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_scores = cross_val_score(log, X_train[:100000], y_train[:100000], scoring=\"f1\")\n",
    "log_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b3bfa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9994315 , 0.99886234, 0.99971599, 0.99914845, 1.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest, X_train[:100000], y_train[:100000], scoring=\"f1\")\n",
    "forest_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad6b78e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9583815 , 0.95888014, 0.96309212, 0.97677086, 0.97088498])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_scores = cross_val_score(svm, X_train[:100000], y_train[:100000], scoring=\"f1\")\n",
    "svm_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162b2fb",
   "metadata": {},
   "source": [
    "Random forest trees seem to perform the best on different training and testing splits. So for the given timeline we will not go further on model selection and I will settle on random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e025e",
   "metadata": {},
   "source": [
    "However It will take a lot of time to fit 1m observations on a randomforest model for a regular computer, but for the purpose of this project I will have to perform this computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603aed8",
   "metadata": {},
   "source": [
    "And i will have to use methods to set good parameters to maximize model \"security\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
